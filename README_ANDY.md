# Andy - Assistant DevOps Autonome v0.5

Assistant d'installation automatisÃ© pour LLMUI Core dÃ©veloppÃ© par GÃ©nie IA Centre OpÃ©rationnel SÃ©curitÃ© inc.

## ğŸ¯ CaractÃ©ristiques

- âœ“ **100% autonome** - Suit les commandes pas Ã  pas
- âœ“ **Base SQLite intÃ©grÃ©e** - Stocke commandes, notes, corrections
- âœ“ **Gestion d'erreurs intelligente** - DÃ©tecte et adapte automatiquement
- âœ“ **Multi-OS** - Support apt, dnf, yum
- âœ“ **Installation Ollama** - Automatique avec modÃ¨les phi3, gemma2, granite4
- âœ“ **Logging complet** - TraÃ§abilitÃ© totale
- âœ“ **VÃ©rification post-installation** - Tests automatiques

## ğŸ“‹ PrÃ©requis

- Debian/Ubuntu/RHEL/Rocky Linux
- Python 3.8+
- AccÃ¨s root (sudo)
- 20GB d'espace disque minimum
- 4GB RAM minimum (8GB recommandÃ©)

## ğŸš€ Installation en 3 Ã©tapes

### Ã‰tape 1: Installation de base
```bash
sudo python3 andy_installer.py
```

Cette Ã©tape installe:
- Mise Ã  jour OS
- DÃ©pendances systÃ¨me (nginx, sqlite3, etc.)
- Ollama + modÃ¨les LLM
- Environnement virtuel Python
- Services systemd (backend, proxy)
- Configuration Nginx
- Pare-feu (UFW/firewalld)

**Andy vous demandera:**
- Nom d'utilisateur pour LLMUI (dÃ©faut: llmui)
- Mot de passe pour l'interface web

### Ã‰tape 2: DÃ©ploiement des sources
```bash
sudo python3 andy_deploy_source.py
```

Options:
- **Avec Git**: Entrez l'URL du dÃ©pÃ´t (public ou privÃ©)
- **Manuellement**: Copiez les fichiers vers `/opt/llmui-core/`

Structure requise:
```
/opt/llmui-core/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ llmui_backend.py
â”‚   â”œâ”€â”€ llmui_proxy.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ ...
â””â”€â”€ config.yaml
```

### Ã‰tape 3: DÃ©marrage des services
```bash
sudo python3 andy_start_services.py
```

Cette Ã©tape:
- VÃ©rifie la prÃ©sence des fichiers source
- DÃ©marre les services systemd
- Teste la disponibilitÃ©
- Affiche l'URL d'accÃ¨s

## ğŸ“Š Fichiers gÃ©nÃ©rÃ©s

| Fichier | Description |
|---------|-------------|
| `/tmp/andy_install.log` | Log complet de l'installation |
| `/tmp/andy_installation.db` | Base SQLite avec historique |
| `/opt/llmui-core/` | Installation LLMUI |
| `/etc/systemd/system/llmui-*.service` | Services systemd |
| `/etc/nginx/sites-available/llmui` | Configuration Nginx |

## ğŸ” VÃ©rifications post-installation

### Statut des services
```bash
sudo systemctl status llmui-backend
sudo systemctl status llmui-proxy
sudo systemctl status nginx
```

### Logs en temps rÃ©el
```bash
# Backend
sudo journalctl -u llmui-backend -f

# Proxy
sudo journalctl -u llmui-proxy -f

# Nginx
sudo tail -f /var/log/nginx/llmui-access.log
```

### Test de l'interface
```bash
curl -I http://localhost/
curl http://localhost/api/health
```

## ğŸ”§ Commandes utiles

### RedÃ©marrer les services
```bash
sudo systemctl restart llmui-backend
sudo systemctl restart llmui-proxy
sudo systemctl restart nginx
```

### Consulter la base de donnÃ©es d'Andy
```bash
sqlite3 /tmp/andy_installation.db

# Voir les commandes exÃ©cutÃ©es
SELECT * FROM commands ORDER BY timestamp DESC;

# Voir les notes d'Andy
SELECT * FROM andy_notes ORDER BY timestamp DESC;

# Voir les corrections appliquÃ©es
SELECT * FROM corrections ORDER BY timestamp DESC;
```

### RÃ©installer proprement
```bash
# ArrÃªter les services
sudo systemctl stop llmui-backend llmui-proxy

# Supprimer l'installation
sudo rm -rf /opt/llmui-core
sudo userdel -r admin  # ou le nom d'utilisateur choisi

# Supprimer les services
sudo rm /etc/systemd/system/llmui-*.service
sudo systemctl daemon-reload

# Relancer l'installation
sudo python3 andy_installer.py
```

## ğŸ› DÃ©pannage

### Les services ne dÃ©marrent pas

1. VÃ©rifier les logs:
```bash
sudo journalctl -u llmui-backend -n 50
```

2. VÃ©rifier les permissions:
```bash
ls -la /opt/llmui-core/src/
```

3. VÃ©rifier l'environnement virtuel:
```bash
/opt/llmui-core/venv/bin/python --version
/opt/llmui-core/venv/bin/pip list
```

### Nginx erreur 502

Le backend n'est probablement pas dÃ©marrÃ©:
```bash
sudo systemctl status llmui-backend
sudo journalctl -u llmui-backend -n 20
```

### Ollama ne rÃ©pond pas

```bash
ollama list
ollama ps
sudo systemctl status ollama
```

### ProblÃ¨mes de pare-feu

```bash
# UFW
sudo ufw status verbose

# Firewalld
sudo firewall-cmd --list-all
```

## ğŸ“ Configuration personnalisÃ©e

### Modifier la configuration LLMUI

Ã‰ditez `/opt/llmui-core/config.yaml` puis:
```bash
sudo systemctl restart llmui-backend llmui-proxy
```

### Ajouter un certificat SSL

```bash
sudo certbot --nginx -d votre-domaine.com
```

### Changer le port

Ã‰ditez `/etc/nginx/sites-available/llmui` et changez `listen 80;`

## ğŸ” SÃ©curitÃ©

Andy configure automatiquement:
- Pare-feu avec rÃ¨gles restrictives
- Headers de sÃ©curitÃ© Nginx
- Permissions strictes sur les fichiers
- Services systemd avec isolation

**Recommandations supplÃ©mentaires:**
- Utilisez SSL/TLS (certbot)
- Configurez fail2ban pour le SSH
- Mettez Ã  jour rÃ©guliÃ¨rement l'OS
- Utilisez des mots de passe forts

## ğŸ“ Support

- Logs: `/tmp/andy_install.log`
- Base de donnÃ©es: `/tmp/andy_installation.db`
- Documentation LLMUI: Consultez votre dÃ©pÃ´t Git

## ğŸ“ Structure du projet Andy

```
andy_installer.py       # Installation de base
andy_deploy_source.py   # DÃ©ploiement fichiers source
andy_start_services.py  # DÃ©marrage services
README_ANDY.md          # Cette documentation
```

## ğŸ“œ Licence

PropriÃ©taire - GÃ©nie IA Centre OpÃ©rationnel SÃ©curitÃ© inc.

---

**Version:** 0.5  
**ModÃ¨le LLM:** qwen2.5:3b  
**Auteur:** FranÃ§ois, GÃ©nie IA Centre OpÃ©rationnel SÃ©curitÃ© inc.  
**Date:** 2025-11-21
