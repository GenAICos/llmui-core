#!/bin/bash
# -*- coding: utf-8 -*-
#
# LLMUI Core v2.0 - Script de test automatique complet
# Author: FranÃ§ois Chalut
# Website: https://llmui.org
#
# Ce script teste l'intÃ©gralitÃ© de l'installation LLMUI Core

set -e

# Couleurs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Compteurs
TESTS_TOTAL=0
TESTS_PASSED=0
TESTS_FAILED=0
TESTS_SKIPPED=0

# Logs
LOG_FILE="/tmp/llmui_test_$(date +%Y%m%d_%H%M%S).log"

# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

log() {
    echo -e "$1" | tee -a "$LOG_FILE"
}

test_start() {
    TESTS_TOTAL=$((TESTS_TOTAL + 1))
    echo -ne "${BLUE}[TEST $TESTS_TOTAL]${NC} $1... "
    echo "[TEST $TESTS_TOTAL] $1..." >> "$LOG_FILE"
}

test_pass() {
    TESTS_PASSED=$((TESTS_PASSED + 1))
    log "${GREEN}âœ… PASS${NC}"
}

test_fail() {
    TESTS_FAILED=$((TESTS_FAILED + 1))
    log "${RED}âŒ FAIL${NC}"
    if [ -n "$1" ]; then
        log "${RED}   Raison: $1${NC}"
    fi
}

test_skip() {
    TESTS_SKIPPED=$((TESTS_SKIPPED + 1))
    log "${YELLOW}âš ï¸  SKIP${NC}"
    if [ -n "$1" ]; then
        log "${YELLOW}   Raison: $1${NC}"
    fi
}

# ============================================================================
# HEADER
# ============================================================================

clear
log ""
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log "  LLMUI CORE v2.0 - TEST AUTOMATIQUE COMPLET"
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log "  Date: $(date)"
log "  Log: $LOG_FILE"
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log ""

# ============================================================================
# SECTION 1: TESTS SYSTÃˆME
# ============================================================================

log "${BLUE}â”â”â” SECTION 1: TESTS SYSTÃˆME â”â”â”${NC}"
log ""

# Test 1.1: OS
test_start "VÃ©rification du systÃ¨me d'exploitation"
if [[ -f /etc/os-release ]]; then
    OS_NAME=$(grep "^NAME=" /etc/os-release | cut -d'"' -f2)
    OS_VERSION=$(grep "^VERSION=" /etc/os-release | cut -d'"' -f2)
    log "   OS: $OS_NAME $OS_VERSION" >> "$LOG_FILE"
    test_pass
else
    test_fail "Impossible de dÃ©tecter l'OS"
fi

# Test 1.2: Architecture
test_start "VÃ©rification de l'architecture"
ARCH=$(uname -m)
if [[ "$ARCH" == "x86_64" ]] || [[ "$ARCH" == "aarch64" ]]; then
    log "   Architecture: $ARCH" >> "$LOG_FILE"
    test_pass
else
    test_fail "Architecture non supportÃ©e: $ARCH"
fi

# Test 1.3: RAM
test_start "VÃ©rification de la RAM"
TOTAL_RAM=$(free -g | awk '/^Mem:/{print $2}')
if [ "$TOTAL_RAM" -ge 8 ]; then
    log "   RAM totale: ${TOTAL_RAM}GB" >> "$LOG_FILE"
    test_pass
else
    test_fail "RAM insuffisante: ${TOTAL_RAM}GB (minimum 8GB recommandÃ©)"
fi

# Test 1.4: Espace disque
test_start "VÃ©rification de l'espace disque"
DISK_AVAIL=$(df -BG /opt 2>/dev/null | awk 'NR==2 {print $4}' | tr -d 'G')
if [ "$DISK_AVAIL" -ge 10 ]; then
    log "   Espace disponible: ${DISK_AVAIL}GB" >> "$LOG_FILE"
    test_pass
else
    test_fail "Espace disque insuffisant: ${DISK_AVAIL}GB (minimum 10GB)"
fi

log ""

# ============================================================================
# SECTION 2: TESTS DÃ‰PENDANCES
# ============================================================================

log "${BLUE}â”â”â” SECTION 2: TESTS DÃ‰PENDANCES â”â”â”${NC}"
log ""

# Test 2.1: Python
test_start "VÃ©rification de Python"
if command -v python3 &> /dev/null; then
    PY_VERSION=$(python3 --version | cut -d' ' -f2)
    log "   Python version: $PY_VERSION" >> "$LOG_FILE"
    test_pass
else
    test_fail "Python 3 non trouvÃ©"
fi

# Test 2.2: pip
test_start "VÃ©rification de pip"
if command -v pip3 &> /dev/null; then
    PIP_VERSION=$(pip3 --version | cut -d' ' -f2)
    log "   pip version: $PIP_VERSION" >> "$LOG_FILE"
    test_pass
else
    test_fail "pip3 non trouvÃ©"
fi

# Test 2.3: Ollama
test_start "VÃ©rification d'Ollama"
if command -v ollama &> /dev/null; then
    OLLAMA_VERSION=$(ollama --version 2>&1 | head -1)
    log "   Ollama version: $OLLAMA_VERSION" >> "$LOG_FILE"
    test_pass
else
    test_fail "Ollama non trouvÃ©"
fi

# Test 2.4: Redis (optionnel)
test_start "VÃ©rification de Redis"
if command -v redis-cli &> /dev/null; then
    REDIS_VERSION=$(redis-cli --version | cut -d' ' -f2)
    log "   Redis version: $REDIS_VERSION" >> "$LOG_FILE"
    test_pass
else
    test_skip "Redis non installÃ© (optionnel)"
fi

log ""

# ============================================================================
# SECTION 3: TESTS INSTALLATION
# ============================================================================

log "${BLUE}â”â”â” SECTION 3: TESTS INSTALLATION â”â”â”${NC}"
log ""

INSTALL_DIR="/opt/llmui-core"
DATA_DIR="/var/lib/llmui"
LOG_DIR="/var/log/llmui"

# Test 3.1: RÃ©pertoire d'installation
test_start "VÃ©rification du rÃ©pertoire d'installation"
if [ -d "$INSTALL_DIR" ]; then
    test_pass
else
    test_fail "RÃ©pertoire $INSTALL_DIR non trouvÃ©"
fi

# Test 3.2: Fichiers Python
test_start "VÃ©rification des fichiers Python"
REQUIRED_FILES=(
    "$INSTALL_DIR/src/__init__.py"
    "$INSTALL_DIR/src/llmui_backend.py"
    "$INSTALL_DIR/src/llmui_proxy.py"
    "$INSTALL_DIR/src/memory.py"
)
ALL_EXIST=true
for file in "${REQUIRED_FILES[@]}"; do
    if [ ! -f "$file" ]; then
        ALL_EXIST=false
        log "   Manquant: $file" >> "$LOG_FILE"
    fi
done
if $ALL_EXIST; then
    test_pass
else
    test_fail "Certains fichiers Python sont manquants"
fi

# Test 3.3: Fichiers Web
test_start "VÃ©rification des fichiers Web"
WEB_FILES=(
    "$INSTALL_DIR/web/index.html"
    "$INSTALL_DIR/web/js/llmui-main.js"
    "$INSTALL_DIR/web/css/llmui-styles.css"
)
ALL_EXIST=true
for file in "${WEB_FILES[@]}"; do
    if [ ! -f "$file" ]; then
        ALL_EXIST=false
        log "   Manquant: $file" >> "$LOG_FILE"
    fi
done
if $ALL_EXIST; then
    test_pass
else
    test_fail "Certains fichiers Web sont manquants"
fi

# Test 3.4: Scripts
test_start "VÃ©rification des scripts"
SCRIPTS=(
    "$INSTALL_DIR/scripts/install.sh"
    "$INSTALL_DIR/scripts/uninstall.sh"
    "$INSTALL_DIR/scripts/start.sh"
)
ALL_EXEC=true
for script in "${SCRIPTS[@]}"; do
    if [ ! -x "$script" ]; then
        ALL_EXEC=false
        log "   Non exÃ©cutable: $script" >> "$LOG_FILE"
    fi
done
if $ALL_EXEC; then
    test_pass
else
    test_fail "Certains scripts ne sont pas exÃ©cutables"
fi

# Test 3.5: Environnement virtuel Python
test_start "VÃ©rification de l'environnement virtuel Python"
if [ -d "$INSTALL_DIR/venv" ]; then
    test_pass
else
    test_fail "venv non trouvÃ©"
fi

# Test 3.6: DÃ©pendances Python
test_start "VÃ©rification des dÃ©pendances Python"
if [ -f "$INSTALL_DIR/venv/bin/python" ]; then
    FASTAPI_INSTALLED=$("$INSTALL_DIR/venv/bin/python" -c "import fastapi" 2>/dev/null && echo "yes" || echo "no")
    if [ "$FASTAPI_INSTALLED" == "yes" ]; then
        test_pass
    else
        test_fail "FastAPI non installÃ© dans venv"
    fi
else
    test_fail "Python venv non trouvÃ©"
fi

log ""

# ============================================================================
# SECTION 4: TESTS BASE DE DONNÃ‰ES
# ============================================================================

log "${BLUE}â”â”â” SECTION 4: TESTS BASE DE DONNÃ‰ES â”â”â”${NC}"
log ""

# Test 4.1: Existence base de donnÃ©es
test_start "VÃ©rification de la base de donnÃ©es SQLite"
if [ -f "$DATA_DIR/llmui.db" ]; then
    test_pass
else
    test_fail "Base de donnÃ©es non trouvÃ©e"
fi

# Test 4.2: Permissions base de donnÃ©es
test_start "VÃ©rification des permissions de la base de donnÃ©es"
if [ -f "$DATA_DIR/llmui.db" ]; then
    PERMS=$(stat -c "%a" "$DATA_DIR/llmui.db")
    if [ "$PERMS" == "660" ] || [ "$PERMS" == "600" ]; then
        test_pass
    else
        test_fail "Permissions incorrectes: $PERMS (attendu: 660 ou 600)"
    fi
else
    test_skip "Base de donnÃ©es non trouvÃ©e"
fi

# Test 4.3: Tables SQLite
test_start "VÃ©rification des tables SQLite"
if [ -f "$DATA_DIR/llmui.db" ]; then
    TABLES=$(sqlite3 "$DATA_DIR/llmui.db" ".tables" 2>/dev/null || echo "")
    if [[ "$TABLES" == *"conversations"* ]] && [[ "$TABLES" == *"stats"* ]]; then
        test_pass
    else
        test_fail "Tables manquantes"
    fi
else
    test_skip "Base de donnÃ©es non trouvÃ©e"
fi

log ""

# ============================================================================
# SECTION 5: TESTS SERVICES
# ============================================================================

log "${BLUE}â”â”â” SECTION 5: TESTS SERVICES â”â”â”${NC}"
log ""

# Test 5.1: Service systemd backend
test_start "VÃ©rification du service llmui-backend"
if systemctl is-active --quiet llmui-backend; then
    test_pass
else
    test_fail "Service llmui-backend non actif"
fi

# Test 5.2: Service systemd proxy
test_start "VÃ©rification du service llmui-proxy"
if systemctl is-active --quiet llmui-proxy; then
    test_pass
else
    test_fail "Service llmui-proxy non actif"
fi

# Test 5.3: Service Ollama
test_start "VÃ©rification du service Ollama"
if systemctl is-active --quiet ollama 2>/dev/null; then
    test_pass
else
    # Ollama peut ne pas Ãªtre un service systemd
    if pgrep -x "ollama" > /dev/null; then
        test_pass
    else
        test_fail "Service Ollama non actif"
    fi
fi

log ""

# ============================================================================
# SECTION 6: TESTS RÃ‰SEAU
# ============================================================================

log "${BLUE}â”â”â” SECTION 6: TESTS RÃ‰SEAU â”â”â”${NC}"
log ""

# Test 6.1: Port backend (5000)
test_start "VÃ©rification du port backend (5000)"
if netstat -tuln 2>/dev/null | grep -q ":5000 " || ss -tuln 2>/dev/null | grep -q ":5000 "; then
    test_pass
else
    test_fail "Port 5000 non ouvert"
fi

# Test 6.2: Port proxy (8000)
test_start "VÃ©rification du port proxy (8000)"
if netstat -tuln 2>/dev/null | grep -q ":8000 " || ss -tuln 2>/dev/null | grep -q ":8000 "; then
    test_pass
else
    test_fail "Port 8000 non ouvert"
fi

# Test 6.3: Port Ollama (11434)
test_start "VÃ©rification du port Ollama (11434)"
if netstat -tuln 2>/dev/null | grep -q ":11434 " || ss -tuln 2>/dev/null | grep -q ":11434 "; then
    test_pass
else
    test_fail "Port 11434 non ouvert"
fi

# Test 6.4: Port Redis (6379) - optionnel
test_start "VÃ©rification du port Redis (6379)"
if netstat -tuln 2>/dev/null | grep -q ":6379 " || ss -tuln 2>/dev/null | grep -q ":6379 "; then
    test_pass
else
    test_skip "Redis non actif (optionnel)"
fi

log ""

# ============================================================================
# SECTION 7: TESTS API
# ============================================================================

log "${BLUE}â”â”â” SECTION 7: TESTS API â”â”â”${NC}"
log ""

# Test 7.1: Health endpoint backend
test_start "Test de l'endpoint /health"
HEALTH_RESPONSE=$(curl -s -w "\n%{http_code}" http://localhost:5000/health 2>/dev/null)
HTTP_CODE=$(echo "$HEALTH_RESPONSE" | tail -1)
if [ "$HTTP_CODE" == "200" ]; then
    test_pass
else
    test_fail "Code HTTP: $HTTP_CODE (attendu: 200)"
fi

# Test 7.2: Models endpoint
test_start "Test de l'endpoint /api/models"
MODELS_RESPONSE=$(curl -s -w "\n%{http_code}" http://localhost:5000/api/models 2>/dev/null)
HTTP_CODE=$(echo "$MODELS_RESPONSE" | tail -1)
if [ "$HTTP_CODE" == "200" ]; then
    test_pass
else
    test_fail "Code HTTP: $HTTP_CODE (attendu: 200)"
fi

# Test 7.3: Timeout levels endpoint
test_start "Test de l'endpoint /api/timeout-levels"
TIMEOUT_RESPONSE=$(curl -s -w "\n%{http_code}" http://localhost:5000/api/timeout-levels 2>/dev/null)
HTTP_CODE=$(echo "$TIMEOUT_RESPONSE" | tail -1)
if [ "$HTTP_CODE" == "200" ]; then
    test_pass
else
    test_fail "Code HTTP: $HTTP_CODE (attendu: 200)"
fi

# Test 7.4: Stats endpoint
test_start "Test de l'endpoint /api/stats"
STATS_RESPONSE=$(curl -s -w "\n%{http_code}" http://localhost:5000/api/stats 2>/dev/null)
HTTP_CODE=$(echo "$STATS_RESPONSE" | tail -1)
if [ "$HTTP_CODE" == "200" ]; then
    test_pass
else
    test_fail "Code HTTP: $HTTP_CODE (attendu: 200)"
fi

# Test 7.5: Proxy - page d'accueil
test_start "Test de l'interface web via proxy"
WEB_RESPONSE=$(curl -s -w "\n%{http_code}" http://localhost:8000/ 2>/dev/null)
HTTP_CODE=$(echo "$WEB_RESPONSE" | tail -1)
if [ "$HTTP_CODE" == "200" ]; then
    test_pass
else
    test_fail "Code HTTP: $HTTP_CODE (attendu: 200)"
fi

log ""

# ============================================================================
# SECTION 8: TESTS OLLAMA
# ============================================================================

log "${BLUE}â”â”â” SECTION 8: TESTS OLLAMA â”â”â”${NC}"
log ""

# Test 8.1: Ollama list
test_start "Liste des modÃ¨les Ollama"
if command -v ollama &> /dev/null; then
    MODEL_COUNT=$(ollama list 2>/dev/null | tail -n +2 | wc -l)
    if [ "$MODEL_COUNT" -ge 4 ]; then
        log "   ModÃ¨les trouvÃ©s: $MODEL_COUNT" >> "$LOG_FILE"
        test_pass
    else
        test_fail "ModÃ¨les insuffisants: $MODEL_COUNT (minimum 4)"
    fi
else
    test_skip "Ollama non disponible"
fi

# Test 8.2: ModÃ¨les requis
test_start "VÃ©rification des modÃ¨les requis"
if command -v ollama &> /dev/null; then
    REQUIRED_MODELS=("granite3.1:2b" "phi3:3.8b" "mistral:7b" "qwen2.5:3b")
    ALL_PRESENT=true
    for model in "${REQUIRED_MODELS[@]}"; do
        if ! ollama list 2>/dev/null | grep -q "$model"; then
            ALL_PRESENT=false
            log "   Manquant: $model" >> "$LOG_FILE"
        fi
    done
    if $ALL_PRESENT; then
        test_pass
    else
        test_fail "Certains modÃ¨les requis sont manquants"
    fi
else
    test_skip "Ollama non disponible"
fi

log ""

# ============================================================================
# SECTION 9: TESTS PERMISSIONS
# ============================================================================

log "${BLUE}â”â”â” SECTION 9: TESTS PERMISSIONS â”â”â”${NC}"
log ""

# Test 9.1: Utilisateur llmui
test_start "VÃ©rification de l'utilisateur systÃ¨me llmui"
if id -u llmui &>/dev/null; then
    test_pass
else
    test_fail "Utilisateur llmui non trouvÃ©"
fi

# Test 9.2: PropriÃ©taire des fichiers
test_start "VÃ©rification du propriÃ©taire des fichiers"
if [ -d "$INSTALL_DIR" ]; then
    OWNER=$(stat -c "%U" "$INSTALL_DIR")
    if [ "$OWNER" == "llmui" ] || [ "$OWNER" == "root" ]; then
        test_pass
    else
        test_fail "PropriÃ©taire incorrect: $OWNER"
    fi
else
    test_skip "RÃ©pertoire d'installation non trouvÃ©"
fi

# Test 9.3: Permissions logs
test_start "VÃ©rification des permissions des logs"
if [ -d "$LOG_DIR" ]; then
    PERMS=$(stat -c "%a" "$LOG_DIR")
    if [ "$PERMS" == "755" ] || [ "$PERMS" == "750" ]; then
        test_pass
    else
        test_fail "Permissions logs incorrectes: $PERMS"
    fi
else
    test_skip "RÃ©pertoire de logs non trouvÃ©"
fi

log ""

# ============================================================================
# SECTION 10: TESTS FONCTIONNELS
# ============================================================================

log "${BLUE}â”â”â” SECTION 10: TESTS FONCTIONNELS â”â”â”${NC}"
log ""

# Test 10.1: GÃ©nÃ©ration simple
test_start "Test de gÃ©nÃ©ration simple"
SIMPLE_TEST=$(curl -s -X POST http://localhost:5000/api/simple-generate \
    -H "Content-Type: application/json" \
    -d '{
        "model": "qwen2.5:3b",
        "prompt": "Say hello in one word",
        "session_id": "test_session",
        "timeout_level": "low"
    }' 2>/dev/null)

if echo "$SIMPLE_TEST" | grep -q '"success":true'; then
    test_pass
else
    test_fail "GÃ©nÃ©ration simple Ã©chouÃ©e"
fi

# Test 10.2: Statistiques
test_start "Test de rÃ©cupÃ©ration des statistiques"
STATS_TEST=$(curl -s http://localhost:5000/api/stats 2>/dev/null)
if echo "$STATS_TEST" | grep -q '"success":true'; then
    test_pass
else
    test_fail "RÃ©cupÃ©ration des statistiques Ã©chouÃ©e"
fi

# Test 10.3: Interface web
test_start "Test du chargement de l'interface web"
WEB_TEST=$(curl -s http://localhost:8000/ 2>/dev/null)
if echo "$WEB_TEST" | grep -q "LLMUI Core"; then
    test_pass
else
    test_fail "Interface web non chargÃ©e correctement"
fi

log ""

# ============================================================================
# SECTION 11: TESTS LOGS
# ============================================================================

log "${BLUE}â”â”â” SECTION 11: TESTS LOGS â”â”â”${NC}"
log ""

# Test 11.1: Fichier log backend
test_start "VÃ©rification du fichier log backend"
if [ -f "$LOG_DIR/backend.log" ]; then
    test_pass
else
    test_fail "Fichier backend.log non trouvÃ©"
fi

# Test 11.2: Fichier log proxy
test_start "VÃ©rification du fichier log proxy"
if [ -f "$LOG_DIR/proxy.log" ]; then
    test_pass
else
    test_fail "Fichier proxy.log non trouvÃ©"
fi

# Test 11.3: Erreurs dans les logs
test_start "Recherche d'erreurs critiques dans les logs"
if [ -f "$LOG_DIR/backend.log" ]; then
    ERROR_COUNT=$(grep -i "error\|exception\|traceback" "$LOG_DIR/backend.log" 2>/dev/null | wc -l)
    if [ "$ERROR_COUNT" -eq 0 ]; then
        test_pass
    else
        test_fail "$ERROR_COUNT erreur(s) trouvÃ©e(s) dans les logs"
    fi
else
    test_skip "Logs backend non trouvÃ©s"
fi

log ""

# ============================================================================
# SECTION 12: TESTS SÃ‰CURITÃ‰
# ============================================================================

log "${BLUE}â”â”â” SECTION 12: TESTS SÃ‰CURITÃ‰ â”â”â”${NC}"
log ""

# Test 12.1: Configuration admin
test_start "VÃ©rification du fichier de configuration admin"
if [ -f "/etc/llmui/admin.conf" ]; then
    test_pass
else
    test_fail "Fichier admin.conf non trouvÃ©"
fi

# Test 12.2: Permissions admin.conf
test_start "VÃ©rification des permissions admin.conf"
if [ -f "/etc/llmui/admin.conf" ]; then
    PERMS=$(stat -c "%a" "/etc/llmui/admin.conf")
    if [ "$PERMS" == "600" ]; then
        test_pass
    else
        test_fail "Permissions admin.conf: $PERMS (attendu: 600)"
    fi
else
    test_skip "Fichier admin.conf non trouvÃ©"
fi

# Test 12.3: SSL (si activÃ©)
test_start "VÃ©rification des certificats SSL"
if [ -f "$INSTALL_DIR/ssl/llmui.crt" ] && [ -f "$INSTALL_DIR/ssl/llmui.key" ]; then
    test_pass
else
    test_skip "SSL non configurÃ©"
fi

log ""

# ============================================================================
# RÃ‰SUMÃ‰ FINAL
# ============================================================================

log ""
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log "  RÃ‰SUMÃ‰ DES TESTS"
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log ""
log "  Total de tests:     ${BLUE}$TESTS_TOTAL${NC}"
log "  Tests rÃ©ussis:      ${GREEN}$TESTS_PASSED âœ…${NC}"
log "  Tests Ã©chouÃ©s:      ${RED}$TESTS_FAILED âŒ${NC}"
log "  Tests ignorÃ©s:      ${YELLOW}$TESTS_SKIPPED âš ï¸${NC}"
log ""

# Calcul du pourcentage de rÃ©ussite
if [ $TESTS_TOTAL -gt 0 ]; then
    SUCCESS_RATE=$(echo "scale=1; ($TESTS_PASSED * 100) / $TESTS_TOTAL" | bc)
    log "  Taux de rÃ©ussite:   ${SUCCESS_RATE}%"
    log ""
    
    if [ "$SUCCESS_RATE" == "100.0" ]; then
        log "  ${GREEN}ğŸ‰ EXCELLENT! Tous les tests sont passÃ©s!${NC}"
    elif (( $(echo "$SUCCESS_RATE >= 90" | bc -l) )); then
        log "  ${GREEN}âœ… TRÃˆS BON! Installation fonctionnelle${NC}"
    elif (( $(echo "$SUCCESS_RATE >= 75" | bc -l) )); then
        log "  ${YELLOW}âš ï¸  BON - Quelques amÃ©liorations possibles${NC}"
    elif (( $(echo "$SUCCESS_RATE >= 50" | bc -l) )); then
        log "  ${YELLOW}âš ï¸  MOYEN - Attention requise${NC}"
    else
        log "  ${RED}âŒ CRITIQUE - Installation incomplÃ¨te${NC}"
    fi
fi

log ""
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log "  Log complet sauvegardÃ© dans: $LOG_FILE"
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log ""

# Exit code basÃ© sur le nombre d'Ã©checs
if [ $TESTS_FAILED -eq 0 ]; then
    exit 0
else
    exit 1
fi